# Verification Checklist

> Standard checklists ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö verify Jira issues

---

## Technical Checks (All Issue Types)

### T1: ADF Format
```
‚ñ° Description has type: "doc"
‚ñ° Version is 1
‚ñ° Content array exists
‚ñ° No malformed nodes
```

### T2: Panel Structure
```
‚ñ° Panels have valid panelType (info, success, warning, error, note)
‚ñ° Panel content is array
‚ñ° No nested tables in panels
```

### T3: Inline Code Marks
```
‚ñ° File paths have code marks (e.g., `app/Models/User.ts`)
‚ñ° API routes have code marks (e.g., `/api/v1/credits`)
‚ñ° Component names have code marks (e.g., `CreditHistoryPage`)
‚ñ° Technical terms marked appropriately
```

### T4: Links
```
‚ñ° Parent link exists (for sub-tasks)
‚ñ° Epic link exists (for stories)
‚ñ° Child count matches (for parents)
‚ñ° External links valid (Confluence, docs)
```

### T5: Required Fields
```
‚ñ° Summary filled
‚ñ° Description not empty
‚ñ° Issue type correct
‚ñ° Project key correct (BEP)
‚ñ° Assignee/Reporter set (if required)
```

---

## Story Quality Checks

### S1: INVEST Criteria
```
‚ñ° Independent - ‡πÑ‡∏°‡πà‡∏û‡∏∂‡πà‡∏á‡∏û‡∏≤ story ‡∏≠‡∏∑‡πà‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ deliver value
‚ñ° Negotiable - ‡∏°‡∏µ room ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö discussion
‚ñ° Valuable - ‡∏°‡∏µ business value ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
‚ñ° Estimable - ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô effort ‡πÑ‡∏î‡πâ
‚ñ° Small - ‡∏ó‡∏≥‡πÄ‡∏™‡∏£‡πá‡∏à‡πÉ‡∏ô 1 sprint
‚ñ° Testable - ‡∏ó‡∏∏‡∏Å AC verify ‡πÑ‡∏î‡πâ
```

### S2: Narrative Format
```
‚ñ° Has "As a [persona]"
‚ñ° Has "I want to [action]"
‚ñ° Has "So that [benefit]"
‚ñ° Persona is specific (not generic "user")
‚ñ° Benefit is business value (not technical)
```

### S3: Acceptance Criteria
```
‚ñ° All ACs have Given clause
‚ñ° All ACs have When clause
‚ñ° All ACs have Then clause
‚ñ° ACs are specific (not vague)
‚ñ° ACs are measurable
‚ñ° ACs cover happy path
‚ñ° ACs cover error cases
‚ñ° ACs are independent
```

### S4: Scope Definition
```
‚ñ° Services impacted listed
‚ñ° In-scope clearly defined
‚ñ° Out-of-scope mentioned
‚ñ° Dependencies noted
```

### S5: Language
```
‚ñ° Thai language for content
‚ñ° English for technical terms (‡∏ó‡∏±‡∏ö‡∏®‡∏±‡∏û‡∏ó‡πå)
‚ñ° Consistent throughout
‚ñ° No machine translation artifacts
```

---

## Sub-task Quality Checks

### ST1: Objective
```
‚ñ° Clear 1-2 sentence objective
‚ñ° Answers "what" and "why"
‚ñ° Specific to this sub-task
```

### ST2: Scope & Files
```
‚ñ° File paths are real (not generic)
‚ñ° Paths verified against codebase
‚ñ° Dependencies listed
‚ñ° Related components mentioned
```

### ST3: Acceptance Criteria
```
‚ñ° Given/When/Then format
‚ñ° Specific expected behavior
‚ñ° Error handling covered
‚ñ° Edge cases mentioned
```

### ST4: Tag & Summary
```
‚ñ° Tag matches service: [BE], [FE-Admin], [FE-Web]
‚ñ° Summary is descriptive
‚ñ° Summary starts with tag
```

### ST5: Language
```
‚ñ° Thai + ‡∏ó‡∏±‡∏ö‡∏®‡∏±‡∏û‡∏ó‡πå consistent
‚ñ° Technical terms in English
‚ñ° Code/paths in English
```

---

## QA Sub-task Quality Checks

### QA1: Coverage
```
‚ñ° All Story ACs have test coverage
‚ñ° Happy path covered
‚ñ° Edge cases covered
‚ñ° Error handling covered
```

### QA2: Test Format
```
‚ñ° Test objective clear
‚ñ° Preconditions stated
‚ñ° Steps are specific
‚ñ° Expected results defined
‚ñ° Actual result field (for execution)
```

### QA3: Test Scenarios
```
‚ñ° Scenarios grouped by type (happy, edge, error)
‚ñ° Priority assigned to each test
‚ñ° Panel colors match type:
  - üü¢ success = Happy path
  - üü° warning = Edge cases
  - üî¥ error = Error handling
```

### QA4: Test Data
```
‚ñ° Test data requirements listed
‚ñ° Preconditions for tests defined
‚ñ° Environment requirements noted
```

### QA5: Language
```
‚ñ° Thai + ‡∏ó‡∏±‡∏ö‡∏®‡∏±‡∏û‡∏ó‡πå consistent
‚ñ° Technical terms in English
‚ñ° Clear, actionable language
```

---

## Epic Quality Checks

### E1: Vision
```
‚ñ° Problem statement clear
‚ñ° Target users defined
‚ñ° Business value articulated
‚ñ° Success metrics defined
```

### E2: RICE Score
```
‚ñ° Reach estimated
‚ñ° Impact scored (0.25-3)
‚ñ° Confidence percentage
‚ñ° Effort in weeks
‚ñ° Final score calculated
```

### E3: Scope
```
‚ñ° Must-have features listed
‚ñ° Should-have features listed
‚ñ° Nice-to-have features listed
‚ñ° Out-of-scope defined
```

### E4: User Stories
```
‚ñ° Stories identified (draft)
‚ñ° Stories cover must-have scope
‚ñ° Stories are independent
```

---

## Scoring Guide

### Per Check
| Status | Score | Meaning |
|--------|-------|---------|
| ‚úÖ Pass | 1 | Meets criteria |
| ‚ö†Ô∏è Warning | 0.5 | Partially meets, needs attention |
| ‚ùå Fail | 0 | Does not meet criteria |

### Overall Score
| Score % | Status | Action |
|---------|--------|--------|
| 90-100% | ‚úÖ Pass | Ready |
| 70-89% | ‚ö†Ô∏è Warning | Review recommended |
| < 70% | ‚ùå Fail | Must fix before proceeding |

---

## Auto-Fix Capabilities

| Issue | Can Auto-Fix? | How |
|-------|---------------|-----|
| Missing code marks | ‚úÖ Yes | Detect paths, add marks |
| Language mixed | ‚ö†Ô∏è Partial | Basic translation |
| Missing Given/When/Then | ‚ùå No | Requires understanding |
| Missing panel | ‚úÖ Yes | Wrap in appropriate panel |
| Wrong panel color | ‚úÖ Yes | Change panelType |
| Missing parent link | ‚úÖ Yes | Add via MCP |

---

## Quick Reference

### Verify Story + Sub-tasks
```
/verify-issue BEP-XXX --with-subtasks
```

### Verify and Auto-Fix
```
/verify-issue BEP-XXX --fix
```

### After Creating Story
```
/create-story ‚Üí /verify-issue BEP-XXX
```

### After Full Workflow
```
/story-full ‚Üí /verify-issue BEP-XXX --with-subtasks
```

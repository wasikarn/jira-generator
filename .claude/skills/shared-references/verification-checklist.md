# Verification Checklist

> Standard checklists for verifying Jira issues

---

## Technical Checks (All Issue Types)

### T1: ADF Format

```text
‚ñ° Description has type: "doc"
‚ñ° Version is 1
‚ñ° Content array exists
‚ñ° No malformed nodes
```

### T2: Panel Structure

```text
‚ñ° Panels have valid panelType (info, success, warning, error, note)
‚ñ° Panel content is array
‚ñ° No nested tables in panels
```

### T3: Inline Code Marks

```text
‚ñ° File paths have code marks (e.g., `app/Models/User.ts`)
‚ñ° API routes have code marks (e.g., `/api/v1/credits`)
‚ñ° Component names have code marks (e.g., `CreditHistoryPage`)
‚ñ° Technical terms marked appropriately
```

### T4: Links

```text
‚ñ° Parent link exists (for sub-tasks)
‚ñ° Epic link exists (for stories)
‚ñ° Child count matches (for parents)
‚ñ° External links valid (Confluence, docs)
```

### T5: Required Fields

```text
‚ñ° Summary filled
‚ñ° Description not empty
‚ñ° Issue type correct
‚ñ° Project key correct (BEP)
‚ñ° Assignee/Reporter set (if required)
```

---

## Story Quality Checks

### S1: INVEST Criteria

```text
‚ñ° Independent - Does not depend on other stories to deliver value
‚ñ° Negotiable - Has room for discussion
‚ñ° Valuable - Has clear business value
‚ñ° Estimable - Effort can be estimated
‚ñ° Small - Can be completed in 1 sprint
‚ñ° Testable - All ACs can be verified
```

### S2: Narrative Format

```text
‚ñ° Has "As a [persona]"
‚ñ° Has "I want to [action]"
‚ñ° Has "So that [benefit]"
‚ñ° Persona is specific (not generic "user")
‚ñ° Benefit is business value (not technical)
```

### S3: Acceptance Criteria

```text
‚ñ° All ACs have Given clause
‚ñ° All ACs have When clause
‚ñ° All ACs have Then clause
‚ñ° ACs are specific (not vague)
‚ñ° ACs are measurable
‚ñ° ACs cover happy path
‚ñ° ACs cover error cases
‚ñ° ACs are independent
```

### S4: Scope Definition

```text
‚ñ° Services impacted listed
‚ñ° In-scope clearly defined
‚ñ° Out-of-scope mentioned
‚ñ° Dependencies noted
```

### S5: Language

```text
‚ñ° Thai language for content
‚ñ° English for technical terms (transliteration)
‚ñ° Consistent throughout
‚ñ° No machine translation artifacts
```

---

## Sub-task Quality Checks

### ST1: Objective

```text
‚ñ° Clear 1-2 sentence objective
‚ñ° Answers "what" and "why"
‚ñ° Specific to this sub-task
```

### ST2: Scope & Files

```text
‚ñ° File paths are real (not generic)
‚ñ° Paths verified against codebase
‚ñ° Dependencies listed
‚ñ° Related components mentioned
```

### ST3: Acceptance Criteria

```text
‚ñ° Given/When/Then format
‚ñ° Specific expected behavior
‚ñ° Error handling covered
‚ñ° Edge cases mentioned
```

### ST4: Tag & Summary

```text
‚ñ° Tag matches service: [BE], [FE-Admin], [FE-Web]
‚ñ° Summary is descriptive
‚ñ° Summary starts with tag
```

### ST5: Language

```text
‚ñ° Thai + transliteration consistent
‚ñ° Technical terms in English
‚ñ° Code/paths in English
```

---

## QA Sub-task Quality Checks

### QA1: Coverage

```text
‚ñ° All Story ACs have test coverage
‚ñ° Happy path covered
‚ñ° Edge cases covered
‚ñ° Error handling covered
```

### QA2: Test Format

```text
‚ñ° Test objective clear
‚ñ° Preconditions stated
‚ñ° Steps are specific
‚ñ° Expected results defined
‚ñ° Actual result field (for execution)
```

### QA3: Test Scenarios

```text
‚ñ° Scenarios grouped by type (happy, edge, error)
‚ñ° Priority assigned to each test
‚ñ° Panel colors match type:
  - üü¢ success = Happy path
  - üü° warning = Edge cases
  - üî¥ error = Error handling
```

### QA4: Test Data

```text
‚ñ° Test data requirements listed
‚ñ° Preconditions for tests defined
‚ñ° Environment requirements noted
```

### QA5: Language

```text
‚ñ° Thai + transliteration consistent
‚ñ° Technical terms in English
‚ñ° Clear, actionable language
```

---

## Epic Quality Checks

### E1: Vision

```text
‚ñ° Problem statement clear
‚ñ° Target users defined
‚ñ° Business value articulated
‚ñ° Success metrics defined
```

### E2: RICE Score

```text
‚ñ° Reach estimated
‚ñ° Impact scored (0.25-3)
‚ñ° Confidence percentage
‚ñ° Effort in weeks
‚ñ° Final score calculated
```

### E3: Scope

```text
‚ñ° Must-have features listed
‚ñ° Should-have features listed
‚ñ° Nice-to-have features listed
‚ñ° Out-of-scope defined
```

### E4: User Stories

```text
‚ñ° Stories identified (draft)
‚ñ° Stories cover must-have scope
‚ñ° Stories are independent
```

---

## Hierarchy Alignment Checks (`--with-subtasks` only)

> **Principle:** Use only actual fetched data ‚Äî never guess under any circumstances.
> If unsure which AC maps to which subtask ‚Üí flag as "unclear mapping"

### A1: AC ‚Üî Subtask Coverage

```text
‚ñ° Each Story AC has ‚â•1 subtask backing it
‚ñ° No AC without a subtask to implement it
‚ñ° Mapping is clear (if unclear ‚Üí flag)
```

### A2: Service Tag Match

```text
‚ñ° Story "Services Impacted" ‚Üí all subtask tags covered
‚ñ° No subtask tag outside Story scope
‚ñ° Tags: [BE], [FE-Admin], [FE-Web] match the listed services
```

### A3: Scope Consistency

```text
‚ñ° Story in-scope items ‚Üí subtask objectives fully covered
‚ñ° No scope gap (items in Story but no subtask implements them)
‚ñ° No scope creep (subtask doing more than Story specifies)
```

### A4: Epic ‚Üî Story Fit

```text
‚ñ° Story scope falls within Epic must-have/should-have
‚ñ° Story does not exceed Epic scope
‚ñ° Skip if Story is standalone (no parent Epic)
```

### A5: Parent-Child Links

```text
‚ñ° Every subtask.parent = Story key
‚ñ° Story.parent = Epic key (if applicable)
‚ñ° No orphan subtask
```

### A6: Confluence Alignment

```text
‚ñ° Tech Note content is consistent with Story ACs (if available)
‚ñ° Tech Note does not conflict with subtask details
‚ñ° Skip if no Confluence page exists, flag as info
```

---

## Scoring Guide

### Per Check

| Status | Score | Meaning |
| --- | --- | --- |
| ‚úÖ Pass | 1 | Meets criteria |
| ‚ö†Ô∏è Warning | 0.5 | Partially meets, needs attention |
| ‚ùå Fail | 0 | Does not meet criteria |

### Overall Score

| Score % | Status | Action |
| --- | --- | --- |
| 90-100% | ‚úÖ Pass | Ready |
| 70-89% | ‚ö†Ô∏è Warning | Review recommended |
| < 70% | ‚ùå Fail | Must fix before proceeding |

---

## Auto-Fix Capabilities

| Issue | Can Auto-Fix? | How |
| --- | --- | --- |
| Missing code marks | ‚úÖ Yes | Detect paths, add marks |
| Language mixed | ‚ö†Ô∏è Partial | Basic translation |
| Missing Given/When/Then | ‚ùå No | Requires understanding |
| Missing panel | ‚úÖ Yes | Wrap in appropriate panel |
| Wrong panel color | ‚úÖ Yes | Change panelType |
| Missing parent link | ‚úÖ Yes | Add via MCP |

---

## Quick Reference

### Verify Story + Sub-tasks

```text
/verify-issue BEP-XXX --with-subtasks
```

### Verify and Auto-Fix

```text
/verify-issue BEP-XXX --fix
```

### After Creating Story

```text
/create-story ‚Üí /verify-issue BEP-XXX
```

### After Full Workflow

```text
/story-full ‚Üí /verify-issue BEP-XXX --with-subtasks
```
